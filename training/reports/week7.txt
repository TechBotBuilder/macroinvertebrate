Week 7 Plan:
As noted in week 6's report, I will continue training the best feedfoward model throughout the week until it stops improving.
This three weeks will focus on the development of unsupervised models, which may require some innovation on my part, since the typical unsupervised learning method I have learned about is the Boltzmann machine, which is meant input vectors with binary components, since it essentially settles to a minimal-energy corner of a hypercube. Maybe I can develop this geometrical idea further. Whether I do or not, I will compare training performance between thresholded images (which are binary) and unthresholded images fed to the Boltzmann machine as though working with raw probabilities as in the probabilistic interpretation and shortcut sometimes used in Boltzmann machine learning.
I will also see if there are other unsupervised methods described online that I might be able to implement.
In terms of programming, this week I will write the initial code for unsupervised training, which will be interesting since keras does not have unsupervised learning in its main branch. Next week will be for testing and gridsearch.

Week 7 Report:
I have completed training the large feedforward network, a four-hidden-layer 1024-unit-per-layer, sigmoidal unit network with input images of size 32 by 32 pixels and categorical cross entropy loss function. (Using the adam optimizer method, I have encoded this as ADAMH1024.N256.I32.Asigm.Lcate.D4 when supplied to a training program or returned from gridsearch.)
This network, after 3000 swipes over the training data, achieved the following classification accuracies:
Training 98.5%, validation 24.8%, test 19.9%
The dramatic difference in accuracies between the images trained on and images the network has never seen before shows it has overfitted quite a bit. Conceptually, adding dropout to the network will help this problem, although it would take more training time to reach the same level of accuracy.
While I have made significant progress in continuing last week's work, I have yet to write code for training an unsupervised model. Still, there is a paper describing the learning procedure for restricted boltzmann machines and their deep equivalents in detail at http://www.cs.toronto.edu/~rsalakhu/papers/dbm.pdf. I will implement the restricted boltzmann machine algorithm in code next week and begin training once it is completed.
