Monday Plan:
Most of the work for basic image processing was done last week; to that end, there only remains weeding out the unsuitable (probably photoshopped) images I mentioned in last week's report. That I can do tonight through visual inspection.

For the rest of the week I will begin training something like a support vector machine (SVM). This system takes the input images and uses a large, static, random weight matrix to transform the corresponding input vector into a very high-dimensional encoding vector, which is then run through a nonlinear activation function. This first stage receives no updates and thus does not learn.

Then, the encoding vector runs through a second weight matrix to the layer representing the different categories of macroinvertebrates. This final layer has a softmax activation function, so the category outputs can be treated like the confidence the network places on the image belonging to each category. The second weight matrix is trained relatively quickly.

By the end of the week, I will have a working program that implements this sort of model, including the non-learning property of the first weight matrix. Next week I can evaluate its performance.


Saturday Report:
Research into the abilities of Keras, the neural network library I am using, found that a well-implemented method for keeping a layer static, meaning weight updates for those layers are not needed and not computed, saving time, which is a large reason why SVM-like models are used.

Testing the SVM code has led to promising first signs - nearly one in twelve images are correctly classified right now, versus the approximately one in twenty done with early tests of the general deep neural network program. Comparison among models is not the point yet; I still need next week to maximize the performance of the SVM-like architecture, which can then be compared to the coming weeks' optimized results. Still, it is encouraging to see performance better than seemingly random guesses.

The same preliminary tests of the SVM training program have brought up the issue that my computer may not have sufficient resources for the large computational requirements for learning a classification model of high-dimensional data such as raw images. Several solutions are obvious. Computer GPUs are often used to train artificial neural networks because of their efficiency in matrix operations, and the Keras library supports GPU integration easily; the drawback is that powerful GPUs are expensive. A second possible solution is Amazon's Elastic Compute Cloud, which I have read has been used for similar applications for a low cost. However, the extra time needed to learn how to use such services is prohibitive. Perhaps it is wise to only explore networks that are able to fit on my machine during training, since, beyond experimentation, a goal of this project is to embed the best model in a mobile app such that the classification system can be run on a cell phone as it is needed (running a network is less demanding than training one).

I decided to leave the few images that did not come through processing well as they are, as it can be expected that no data will be without a share of noisy data.
